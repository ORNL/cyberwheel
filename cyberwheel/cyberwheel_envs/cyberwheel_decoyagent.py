import yaml
from importlib.resources import files
from typing import Dict

import gymnasium as gym
from gymnasium import spaces

from network.network_base import Network
from network.host import Host
from .cyberwheel import Cyberwheel
from redagents.killchain_agent import KillChainAgent
from blueagents.decoy_blue import DecoyBlueAgent
from blueagents.observation import HistoryObservation
from detectors.detector import CoinFlipDetector
from red_actions.red_base import RedActionResults
from redagents.killchain_agent import KillChainAgent
from red_actions.red_base import RedActionResults
import random

# import numpy as np

def host_to_index_mapping(network: Network)-> Dict[Host, int]:
    """
    This will help with constructing the obs_vec.
    It will need to be called and save during __init__() 
    because deploying decoy hosts may affect the order of 
    the list network.get_non_decoy_hosts() returns.
    This might not be the case, but this will ensure the 
    original indices are preserved.
    """
    mapping:  Dict[Host, int] = {}
    i = 0
    for host in network.get_nondecoy_hosts():
        mapping[host] = i
        i += 1
    return mapping


class DecoyAgentCyberwheel(gym.Env, Cyberwheel):

    metadata = {"render.modes": ["human"]}

    # def __init__(self, number_hosts, number_subnets, connect_subnets_probability, **kwargs):
    def __init__(
        self, network_config="config.yaml", decoy_host_file="decoy_hosts.yaml", **kwargs
    ):
        network_conf_file = files("cyberwheel.network").joinpath(network_config)
        decoy_conf_file = files("cyberwheel.resources.metadata").joinpath(
            decoy_host_file
        )

        super().__init__(config_file_path=network_conf_file)

        self.max_steps = 100
        self.current_step = 0

        # Create action space. Decoy action for each decoy type for each subnet.
        # Length = num_decoy_host_types * num_subnets
        with open(decoy_conf_file, "r") as f:
            decoy_info = yaml.safe_load(f)
        self.decoy_types = list(decoy_info.keys())
        num_decoys = len(self.decoy_types)
        num_subnets = len(self.network.get_all_subnets)
        num_hosts = len(self.network.get_hosts())

        """
        There needs to be an action for deploying each host on each subnet.
        action_space[0] == which decoy host type to deploy
        action_space[1] == which subnet to deploy it on

        The size of action_space[0] is num_decoys+1 because the agent may
        decide not to deploy a decoy. If action_space[0] == 0, no new hosts
        will be deployed.
        """

        self.action_space = spaces.MultiDiscrete([num_decoys + 1, num_subnets])

        """
        [1 ... 2n], n = number of hosts

        n = 4

        [0, 0, 1, 0, 0, 0, 0, 0]
        [0, 0, 0, 0, 0, 0, 1, 0]
        [0, 1, 0, 0, 0, 0, 1, 0]
        [0, 1, 0, 0, 0, 1, 1, 0]
        [0, 0, 0, 0, 0, 1, 1, 0]

        Changed this to be a 2d vector to make indexing easier:
        v = [[1 ... n],[1 ... n]]
        [[0, 0, 1, 0], [0, 0, 0, 0]]
        v[0] is what is passed by the detector
        v[1] is the history of each host
        """
        self.observation_space = spaces.MultiBinary([num_hosts-1, num_hosts-1])
        self.alert_converter = HistoryObservation(self.observation_space.shape, host_to_index_mapping(self.network))

        hosts = self.network.get_all_hosts()
        user_hosts = []
        for h in hosts:
            if h.host_type != None and "workstation" in h.host_type.name.lower():
                user_hosts.append(h)
        entry_host = random.choice(user_hosts)

        self.red_agent = KillChainAgent(entry_host)
        self.blue_agent = DecoyBlueAgent(self.network)
        self.detector = CoinFlipDetector()
        
    def step(self, action):
        """
        Currently, blue actions don't update the obs_vector. They just make a decoy host
        I'm thinking this will have an affect on the detector. Something like: if a host
        that has the decoy flag set is compromised, then the source host of the attack
        is flagged instead.
        blue_agent.act() should return sum(reward, sum of recurring rewards)
        It should probably provide an empty obs_vec since no updates are made to actual hosts?
        """
        rew = self.blue_agent.act(action)

        """
        I'm thinking that red_agent.act() should return the a RedActionResult. This class is returned by
        red actions and contains:
            - A list of hosts discovered by the network. This is helpful for the red agent and is not needed by step().
            - An unflitered alert generated by the red action. It should be passed to a detector to determine how to
              update the observation vector
            - Whether the action was successful or not
        """
        self.red_agent.act()  # red_action includes action, and target of action

        red_action = self.red_agent.history.red_action_history[-1]  # red action results

        red_alert = (
            red_action.detector_alert
        )  # TODO: Need to filter this red alert through blue detector?

        # red_agent.act()-> RedActionResult
        # detector(rRedActionResult.alert) -> List[Alert]
        # update_obs(List[Alert]->obs_vec)

        red_action_reward: RedActionResults = self.calculate_red_reward(red_action_result)
        alerts = self.detector.obs(red_action_reward.detector_alert)
        obs_vec = self.alert_converter.create_obs_vector(alerts)
        net_reward = red_action_reward + rew

        if self.current_step >= self.max_steps:  # Maximal number of steps
            done = True
        else:
            done = False

        self.current_step += 1

        return self._get_obs(), net_reward, done, False, {}

    def calculate_red_reward(red_action: RedActionResults) -> int:
        if len(red_action.detector_alert.dst_hosts) == 0:
            return 0
        target: Host = red_action.detector_alert.dst_hosts[0]

        if "server" in target.host_type.name:
            # if action == "Discovery" or action == "Reconnaissance": # If its a discovery or recon on a server
            #    reward = -1
            # elif action == "PrivilegeEscalate" or action == "LateralMovement": # If its a privilegescalate or lateralmovement onto server
            #    reward = -10
            # elif action == "Impact": # If its an impact on a server
            #    reward = -100
            reward = red_action.cost * 2
        elif "user" in target.host_type.name:
            # if action == "Discovery" or action == "Reconnaissance": # If its a discovery or recon on a user
            #    reward = -0.5
            # elif action == "PrivilegeEscalate" or action == "LateralMovement": # If its a privilegescalate or lateralmovement onto user
            #    reward = -5
            # elif action == "Impact": # If its an impact on a user
            #    reward = -50
            reward = red_action.cost
        else:
            reward = red_action.cost
        return reward

    def flatten_red_alert(red_alert):
        pass

    def reset(self, seed=None, options=None):

        self.current_step = 0

        # self.network = RandomNetwork(self.number_hosts,self.number_subnets,self.connect_subnets_probability)
        self.network = Network.create_network_from_yaml(self.config_file_path)
        self.red_agent = LongestPathRedAgent(self.network)
        self.blue_agent = DecoyBlueAgent(self.network)

        return self._get_obs(), {}  # observation, info

    # can implement existing GUI here???
    def render(self, mode="human"):
        pass

    # if you open any other processes close them here
    def close(self):
        pass
