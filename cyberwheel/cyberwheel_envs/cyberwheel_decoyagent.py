from importlib.resources import files
import gymnasium as gym
from gymnasium import spaces
from typing import Dict, Iterable, List
import yaml

from .cyberwheel import Cyberwheel
from blueagents.decoy_blue import DecoyBlueAgent
from blueagents.observation import HistoryObservation
from detectors.alert import Alert
from detectors.detector import CoinFlipDetector
from network.network_base import Network
from network.host import Host
from red_actions.red_base import RedActionResults
from redagents.killchain_agent import KillChainAgent
from red_actions.red_base import RedActionResults
import random

# import numpy as np

def host_to_index_mapping(network: Network)-> Dict[Host, int]:
    """
    This will help with constructing the obs_vec.
    It will need to be called and save during __init__() 
    because deploying decoy hosts may affect the order of 
    the list network.get_non_decoy_hosts() returns.
    This might not be the case, but this will ensure the 
    original indices are preserved.
    """
    mapping:  Dict[Host, int] = {}
    i = 0
    for host in network.get_nondecoy_hosts():
        mapping[host.name] = i
        i += 1
    return mapping


class DecoyAgentCyberwheel(gym.Env, Cyberwheel):
    metadata = {"render.modes": ["human"]}

    # def __init__(self, number_hosts, number_subnets, connect_subnets_probability, **kwargs):
    def __init__(
        self, network_config="example_config.yaml", decoy_host_file="decoy_hosts.yaml", host_def_file="host_definitions.yaml", **kwargs
    ):
        network_conf_file = files("cyberwheel.network").joinpath(network_config)
        decoy_conf_file = files("cyberwheel.resources.metadata").joinpath(decoy_host_file)
        host_conf_file = files("cyberwheel.resources.metadata").joinpath(host_def_file)

        super().__init__(config_file_path=network_conf_file)

        self.max_steps = 100
        self.current_step = 0

        # Create action space. Decoy action for each decoy type for each subnet.
        # Length = num_decoy_host_types * num_subnets
        with open(decoy_conf_file, "r") as f:
            self.decoy_info = yaml.safe_load(f)

        with open(host_conf_file, "r") as f:
            self.host_defs = yaml.safe_load(f)['host_types']
        
        self.decoy_types = list(self.decoy_info.keys())

        num_decoys = len(self.decoy_types)
        num_subnets = len(self.network.get_all_subnets())
        num_hosts = len(self.network.get_hosts())
        print(self.decoy_types)
        """
        There needs to be an action for deploying each host on each subnet.
        action_space[0] == which decoy host type to deploy
        action_space[1] == which subnet to deploy it on

        The size of action_space[0] is num_decoys+1 because the agent may
        decide not to deploy a decoy. If action_space[0] == 0, no new hosts
        will be deployed.
        """

        self.action_space = spaces.MultiDiscrete([2*num_decoys+1, num_subnets])
        self.observation_space = spaces.MultiBinary([2, num_hosts])
        self.alert_converter = HistoryObservation(self.observation_space.shape, host_to_index_mapping(self.network))

        hosts = self.network.get_all_hosts()
        user_hosts = []
        for h in hosts:
            if h.host_type != None and "workstation" in h.host_type.name.lower():
                user_hosts.append(h)
        entry_host = random.choice(user_hosts)

        self.red_agent = KillChainAgent(entry_host)
        self.blue_agent = DecoyBlueAgent(self.network, self.decoy_info, self.host_defs)
        self.detector = CoinFlipDetector()
        
    def step(self, action):
        """
        Currently, blue actions don't update the obs_vector. They just make a decoy host
        I'm thinking this will have an affect on the detector. Something like: if a host
        that has the decoy flag set is compromised, then the source host of the attack
        is flagged instead.
        blue_agent.act() should return sum(reward, sum of recurring rewards)
        It should probably provide an empty obs_vec since no updates are made to actual hosts?
        """
        rew = self.blue_agent.act(action) 

        """
        I'm thinking that red_agent.act() should return the a RedActionResult. This class is returned by
        red actions and contains:
            - A list of hosts discovered by the network. This is helpful for the red agent and is not needed by step().
            - An unflitered alert generated by the red action. It should be passed to a detector to determine how to
              update the observation vector
            - Whether the action was successful or not
        """
        self.red_agent.act()  # red_action includes action, and target of action

        red_action_result = self.red_agent.history.red_action_history[-1]  # red action results

        red_alert = red_action_result.detector_alert
          # TODO: Need to filter this red alert through blue detector?

        red_action_reward = self._calculate_red_reward(red_action_result)
        alerts = self.detector.obs(red_alert)
        obs_vec =  self._get_obs(alerts)
        net_reward = red_action_reward + rew

        if self.current_step >= self.max_steps:  # Maximal number of steps
            done = True
        else:
            done = False

        self.current_step += 1

        return obs_vec, net_reward, done, False, {}

    def _calculate_red_reward(self, red_action: RedActionResults) -> int:
        if len(red_action.detector_alert.dst_hosts) == 0:
            return 0
        target: Host = red_action.detector_alert.dst_hosts[0]

        if "server" in target.host_type.name:
            # if action == "Discovery" or action == "Reconnaissance": # If its a discovery or recon on a server
            #    reward = -1
            # elif action == "PrivilegeEscalate" or action == "LateralMovement": # If its a privilegescalate or lateralmovement onto server
            #    reward = -10
            # elif action == "Impact": # If its an impact on a server
            #    reward = -100
            reward = red_action.cost * 2
        elif "user" in target.host_type.name:
            # if action == "Discovery" or action == "Reconnaissance": # If its a discovery or recon on a user
            #    reward = -0.5
            # elif action == "PrivilegeEscalate" or action == "LateralMovement": # If its a privilegescalate or lateralmovement onto user
            #    reward = -5
            # elif action == "Impact": # If its an impact on a user
            #    reward = -50
            reward = red_action.cost
        else:
            reward = red_action.cost
        return reward

    def _get_obs(self, alerts: List[Alert])-> Iterable:
        return self.alert_converter.create_obs_vector(alerts)
    
    def _reset_obs(self)-> Iterable:
        return self.alert_converter.reset_obs_vector()
    def flatten_red_alert(red_alert):
        pass

    def reset(self, seed=None, options=None):
        print("RESET")
        self.current_step = 0
        self.network = Network.create_network_from_yaml(self.config_file_path)
        self.red_agent = KillChainAgent(self.network.get_random_host())
        self.blue_agent = DecoyBlueAgent(self.network, self.decoy_info, self.host_defs)

        self.alert_converter = HistoryObservation(self.observation_space.shape, host_to_index_mapping(self.network))
        self.detector = CoinFlipDetector()

        return self._reset_obs(), {} 

    # can implement existing GUI here???
    def render(self, mode="human"):
        pass

    # if you open any other processes close them here
    def close(self):
        pass
